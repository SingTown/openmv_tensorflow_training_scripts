{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM27GgDK7Wum7qIaf7b+7i0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SingTown/openmv_tensorflow_training_scripts/blob/main/mnist/openmv_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train mnist and Save to OpenMV\n",
        "\n",
        "This Code is for TensorFlow 2\n",
        "\n",
        "reference: https://keras.io/examples/vision/mnist_convnet/"
      ],
      "metadata": {
        "id": "L0HImeGrETRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "xpN0Op4AEP-6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "jwzfGEUiFQcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJHbc4TLE-kx",
        "outputId": "c951216a-f568-41e8-ca19-98664bd46f2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "aVmXPQtiFX2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mRrfyWjFAif",
        "outputId": "f469b0d0-e7f8-4a09-94b1-163d02965352"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Train model"
      ],
      "metadata": {
        "id": "Ud00t4-RFgza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_COrL35Fh4P",
        "outputId": "90ebe622-067f-470e-d7b3-c8a989f199d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 44s 101ms/step - loss: 0.3753 - accuracy: 0.8859 - val_loss: 0.0829 - val_accuracy: 0.9772\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.1114 - accuracy: 0.9663 - val_loss: 0.0582 - val_accuracy: 0.9837\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0843 - accuracy: 0.9735 - val_loss: 0.0554 - val_accuracy: 0.9855\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.0718 - accuracy: 0.9776 - val_loss: 0.0441 - val_accuracy: 0.9867\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.0391 - val_accuracy: 0.9897\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 34s 82ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.0364 - val_accuracy: 0.9900\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0366 - val_accuracy: 0.9893\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.0331 - val_accuracy: 0.9908\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 34s 82ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.0326 - val_accuracy: 0.9908\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.0317 - val_accuracy: 0.9912\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 34s 82ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.0326 - val_accuracy: 0.9915\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0325 - val_accuracy: 0.9917\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 34s 82ms/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.0279 - val_accuracy: 0.9922\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 35s 84ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0323 - val_accuracy: 0.9908\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0293 - val_accuracy: 0.9912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0cc5f3190>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the trained model"
      ],
      "metadata": {
        "id": "-k_wXsaHFoPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOKRmZG6Fnxl",
        "outputId": "a779154a-32e8-431b-af2c-4f2dbfef82f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.025147348642349243\n",
            "Test accuracy: 0.991599977016449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Integer Quantization\n",
        "ref: https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization"
      ],
      "metadata": {
        "id": "wCiAQH4aFuns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import lite\n",
        "\n",
        "def representative_dataset():\n",
        "    for i in range(100):\n",
        "        yield [np.array([x_test[i]])]\n",
        "\n",
        "# Convert the tflite.\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('trained.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRjpzBK8FuGr",
        "outputId": "e5a8e0a4-e559-4df6-9c57-bb19a466375b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Succeed\n",
        "Copy trained.tflite to OpenMV4 H7 or OpenMV4 H7 Plus, run this code in OpenMV: https://github.com/SingTown/openmv_tensorflow_training_scripts/blob/main/mnist/main.py"
      ],
      "metadata": {
        "id": "SWoD4t6YF8Sz"
      }
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SingTown/openmv_tensorflow_training_scripts/blob/main/mobilenet_v2/openmv_mobilenet_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6CEOrWoWLG8"
      },
      "source": [
        "# Train MobilenetV2 and Save to OpenMV\n",
        "\n",
        "This Code is for TensorFlow 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgYMJFPRWGI5"
      },
      "source": [
        "## Download Cats vs Dogs dataset from github\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFwlZAzEWaLR",
        "outputId": "088f303d-7748-4f54-d08c-ceb37d715ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cat_dog'...\n",
            "remote: Enumerating objects: 10018, done.\u001b[K\n",
            "remote: Counting objects: 100% (10018/10018), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10015/10015), done.\u001b[K\n",
            "remote: Total 10018 (delta 3), reused 10017 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (10018/10018), 224.07 MiB | 18.16 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (10011/10011), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch master --depth=1 https://github.com/haritha91/Cats-Dogs-Classifier---Keras.git cat_dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W4gluAgGWfbP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras, lite\n",
        "\n",
        "CLASS_NUM = 2 # dog and cat\n",
        "INPUT_SIZE = 96 #image size is 96 * 96 *3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9LKDHKgWhAB",
        "outputId": "534c0167-58e0-4819-99bc-1ddcc6288105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1/255.0,\n",
        "                    horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.0,)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('cat_dog/dataset/training_set',\n",
        "                          target_size = (INPUT_SIZE, INPUT_SIZE),\n",
        "                          batch_size = 32)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('cat_dog/dataset/test_set',\n",
        "                        target_size = (INPUT_SIZE, INPUT_SIZE),\n",
        "                        batch_size = 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xc0UswWW2CI"
      },
      "source": [
        "## Define Model\n",
        "\n",
        "alpha=0.35 for lower size\n",
        "\n",
        "Note: Do NOT use GlobalAveragePooling2D Which is NOT supported by OpenMV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6oCUM3g9W4Zo",
        "outputId": "c4f9b6ea-67f7-4c8f-c448-a39bcaaff4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.35_96_no_top.h5\n",
            "2019640/2019640 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base = keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    alpha=0.35,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(INPUT_SIZE, INPUT_SIZE, 3)\n",
        ")\n",
        "base.trainable = False\n",
        "\n",
        "x = base.output\n",
        "flatten = keras.layers.Flatten()(x)\n",
        "dropout = keras.layers.Dropout(0.1)(flatten)\n",
        "predictions = keras.layers.Dense(CLASS_NUM, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=base.input, outputs=predictions)\n",
        "#print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzjg_Z5_XBwW"
      },
      "source": [
        "## Train model\n",
        "After 5 epoches, accuracy is about 90%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvZ1SA0LXFKy",
        "outputId": "de38ade4-9052-4df9-d71a-f046ea19b106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 52s 191ms/step - loss: 0.4723 - accuracy: 0.8629 - val_loss: 0.4175 - val_accuracy: 0.8775\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 54s 215ms/step - loss: 0.3206 - accuracy: 0.9034 - val_loss: 0.4868 - val_accuracy: 0.8710\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.2712 - accuracy: 0.9189 - val_loss: 0.4422 - val_accuracy: 0.8950\n",
            "Epoch 4/5\n",
            "250/250 [==============================] - 60s 239ms/step - loss: 0.2186 - accuracy: 0.9330 - val_loss: 0.4492 - val_accuracy: 0.8985\n",
            "Epoch 5/5\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.2022 - accuracy: 0.9385 - val_loss: 0.4685 - val_accuracy: 0.8900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c7c7eb131f0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_set, epochs = 5, validation_data = test_set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMw0ywl2XNd3"
      },
      "source": [
        "## Full Integer Quantization\n",
        "\n",
        "ref: https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXdcxbctXkYi",
        "outputId": "19468367-949a-435f-e58d-196f1e04027b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ],
      "source": [
        "quant_set = test_datagen.flow_from_directory('cat_dog/dataset/test_set',\n",
        "                        target_size = (INPUT_SIZE, INPUT_SIZE),\n",
        "                        batch_size = 1)\n",
        "def representative_dataset():\n",
        "    for i in range(100):\n",
        "        x, y = quant_set.next()\n",
        "        yield [x]\n",
        "\n",
        "# Convert the tflite.\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('trained.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79I1bWyyH9cv"
      },
      "source": [
        "## Succeed\n",
        "\n",
        "Copy trained.tflite to OpenMV4 H7 Plus, run this code in OpenMV4 H7 Plus: https://github.com/SingTown/openmv_tensorflow_training_scripts/blob/main/mobilenet_v2/main.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}